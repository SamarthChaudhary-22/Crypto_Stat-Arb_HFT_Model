import requests
import pandas as pd
import time
import datetime
import os
import sys

# CONFIGURATION
PAIRS_FILE = "cointegrated_pairs.csv"  # File generated by analyzer.py
LIMIT = 5  # Top 5 levels
INTERVAL = 1.0  # Poll every 1 second (to respect rate limits with multiple coins)
DURATION = 300  # Run for 5 minutes


def get_unique_tickers(csv_path):
    """Reads the CSV and extracts a set of all unique tickers involved."""
    if not os.path.exists(csv_path):
        print(f"‚ùå Error: Could not find {csv_path}")
        print("   Run analyzer.py first to generate this file!")
        sys.exit(1)

    df = pd.read_csv(csv_path)
    # Combine Asset1 and Asset2 columns and get unique values
    tickers = set(df['leg1'].unique()) | set(df['leg2'].unique())
    print(f"‚úÖ Loaded {len(tickers)} unique tickers from {len(df)} pairs.")
    return list(tickers)


def get_order_book(session, symbol):
    url = f"https://fapi.binance.com/fapi/v1/depth?symbol={symbol}&limit={LIMIT}"
    try:
        response = session.get(url, timeout=2)
        if response.status_code == 200:
            return response.json()
    except Exception as e:
        pass  # Silently fail on network blips to keep loop running
    return None


def calculate_metrics(bids, asks):
    if not bids or not asks:
        return None, None, None
    # Sum volumes
    v_bids = sum([float(x[1]) for x in bids])
    v_asks = sum([float(x[1]) for x in asks])

    # OBI
    if (v_bids + v_asks) == 0:
        obi = 0
    else:
        obi = (v_bids - v_asks) / (v_bids + v_asks)

    # Micro-Price
    best_bid = float(bids[0][0])
    best_ask = float(asks[0][0])
    mid_price = (best_bid + best_ask) / 2

    if (v_bids + v_asks) == 0:
        micro_price = mid_price
    else:
        micro_price = ((v_bids * best_ask) + (v_asks * best_bid)) / (v_bids + v_asks)

    return obi, micro_price, mid_price


def main():
    # 1. Setup
    tickers = get_unique_tickers(PAIRS_FILE)
    print(f"üî¨ Monitoring: {', '.join(tickers)}")
    print(f"‚è±  Duration: {DURATION} seconds. Press Ctrl+C to stop.\n")

    session = requests.Session()  # Reuse connection for speed
    all_data = []
    start_time = time.time()

    try:
        while (time.time() - start_time) < DURATION:
            loop_start = time.time()
            timestamp = datetime.datetime.now()

            # Loop through every ticker in our portfolio
            for ticker in tickers:
                book = get_order_book(session, ticker)

                if book:
                    bids = book['bids']
                    asks = book['asks']

                    obi, micro_p, mid_p = calculate_metrics(bids, asks)

                    # Store data
                    all_data.append({
                        "timestamp": timestamp,
                        "symbol": ticker,
                        "mid_price": mid_p,
                        "micro_price": micro_p,
                        "obi": obi
                    })

            # Progress Indicator
            elapsed = int(time.time() - start_time)
            print(f"\r‚è≥ Collecting... {elapsed}/{DURATION}s | Rows: {len(all_data)}", end="")

            # Sleep remainder of interval
            cycle_time = time.time() - loop_start
            sleep_time = max(0, INTERVAL - cycle_time)
            time.sleep(sleep_time)

    except KeyboardInterrupt:
        print("\nStopping early...")

    # 2. Save
    print("\n\nüíæ Saving Data...")
    df = pd.DataFrame(all_data)

    # Save raw data
    filename = "microstructure_data_all.csv"
    df.to_csv(filename, index=False)
    print(f"‚úÖ Saved {len(df)} rows to {filename}")


if __name__ == "__main__":
    main()